# MindX：更懂你的智能数字分身

> 一个有脑子又能自我演进成长的数字化分身

## 项目简介

MindX 是一款轻量级、具备思考能力且可自主进化的 AI 个人助理。它率先采用创新的**仿生大脑架构**，最大化发挥本地大模型的能力，让绝大多数日常任务无需云端算力即可完成，仅在必要时调用云端大模型，大幅降低 Token 消耗与算力成本。

MindX 绝非简单的问答系统，而是具备「思考、记忆、执行、进化」完整能力的智能体：
- 🧠 **分层思考**：仿人类大脑的潜意识/主意识分层架构，兼顾响应速度与思考深度
- 📝 **长效记忆**：自动沉淀、整理记忆，越用越贴合你的使用习惯
- 🔧 **灵活扩展**：兼容 OpenClaw 技能生态，支持 MCP 协议，能力边界无限延伸
- 🚀 **自主进化**：基于对话数据训练专属模型，无需复杂操作即可持续适配个人风格
- 🔒 **隐私安全**：100% 本地运行，数据不上传云端，自主可控更安心

## 核心优势

### 🎯 仿生大脑架构，决策更智能
复刻人类大脑思考方式，是 MindX 核心差异化优势：
- **潜意识层**：快速、自动化、低功耗，处理简单交互（如查天气、发消息），极速响应
- **主意识层**：深度、专注、高质量，处理复杂任务（如编程、写代码、做决策），精准可靠
- **核心价值**：算力利用率提升 80%+，自动适配任务复杂度，无需人工干预

### 💰 多元成本控制，智能又省钱
拒绝盲目算力堆砌，聚焦实用价值：
- 轻量场景（查天气、记备忘等）：本地完成，零 Token 消耗、零云端成本
- 专业场景（编程、绘画等）：绑定专属最优模型（GLM/千问/Flux 等），低成本匹配强能力

### 📚 长时记忆系统，越用越懂你
弥补大模型「健忘」短板，仿人类记忆原理打造：
- 记忆自动沉淀：从对话中提取有用信息，长效留存
- 智能整理：自动清理无效记忆，检索效率翻倍
- 本地存储：核心记忆融入本地量化模型，隐私更安全

### 🔄 自我演化能力，持续进化不设限
无需高端硬件，轻松打造专属数字分身：
- 500M 轻量级底模，普通 CPU 即可训练
- 夜间后台自动训练，不占用白天使用时间
- 1 周理解基础偏好，6 个月成为专属「数字分身」

### 🌐 全场景社交兼容，连接无边界
打通全球主流社交渠道，多渠道消息统一处理：
- 覆盖钉钉、微信、QQ、飞书、WhatsApp、Facebook、Telegram 等平台，触达全球 80% 人群常用场景

### 🧰 灵活技能生态 + MCP 协议支持
能力扩展无门槛，生态无限延伸：
- 无缝兼容 OpenClaw 技能，零修改即可上线
- 支持任意编程语言 CLI 开发，技能即插即用
- 原生支持 MCP 协议，统一体验，本地/外部技能无感切换

### 🛠️ 轻量级架构，部署易如反掌
企业级设计，全平台适配：
- Go 语言原生开发，架构稳定、资源占用远低于同类产品
- 嵌入式 KV 数据库支撑亿级数据处理，响应毫秒级
- 单一可执行文件，一键启动，适配 macOS/Linux/Windows

### 🇨🇳 自主可控，更懂中国用户
- 100% 国人自主研发，深度贴合中国用户使用习惯
- 全开源无套路，核心技术自主可控，数据安全有保障

## 快速开始

### 系统要求
- 操作系统：macOS / Linux（Windows 支持即将推出）
- 内存：建议 8GB 以上
- 硬盘空间：建议 20GB 以上
- 网络：首次安装需下载模型，后续可离线使用

### 环境准备
MindX 依赖 Ollama 运行本地大模型，需先安装：

> 注：如果你从发布包中安装，安装脚本会自动帮助你安装 Ollama。

```bash
# macOS（Homebrew）
brew install ollama

# Linux
curl -fsSL https://ollama.com/install.sh | sh

# 启动 Ollama 服务
ollama serve
```

验证安装：
```bash
ollama list  # 显示模型列表（空列表也表示安装成功）
```

### 安装 MindX
#### 方式 1：预编译包（推荐）
1. 下载对应系统的发布包（GitHub Releases）：
   - macOS (Intel): `mindx-v{x.x.x}-darwin-amd64.zip`
   - macOS (Apple Silicon): `mindx-v{x.x.x}-darwin-arm64.zip`
   - Linux (x86_64): `mindx-v{x.x.x}-linux-amd64.tar.gz`

2. 解压并安装：
   ```bash
   # macOS
   unzip mindx-v{x.x.x}-darwin-arm64.zip
   cd mindx-v{x.x.x}
   ./install.sh
   
   # Linux
   tar -xzf mindx-v{x.x.x}-linux-amd64.tar.gz
   cd mindx-v{x.x.x}
   ./install.sh
   ```

3. 启动服务：
   ```bash
   mindx start          # 启动后端服务
   mindx dashboard      # 打开 Web 界面（默认：http://localhost:911）
   # 或使用终端界面
   mindx tui
   ```

#### 方式 2：从源码编译
```bash
# 克隆代码库
git clone https://github.com/yourusername/mindx.git
cd mindx

# 安装依赖（Go 1.21+、Node.js 18+）
# 构建并安装
make install

# 启动
mindx start
```

## 开发与扩展
- **开发环境运行**：`make dev`（后端+前端热重载，访问 http://localhost:5173）
- **技能开发**：兼容 OpenClaw 生态，支持任意编程语言 CLI 开发，即插即用
- **更多功能**：可访问 [MindX](https://mindx.chat) 官方网站查看更多功能

## 常见问题
- **Q: 安装提示 Ollama 未安装？**  
  A: 确保 Ollama 已正确安装并启动服务（验证：`ollama list`）。
- **Q: 如何更新 MindX？**  
  A: 下载最新发布包，重新运行 `install.sh` 即可。
- **Q: 数据存储位置？**  
  A: 所有数据（对话、记忆、配置）均存储在安装时指定的本地工作目录。
- **Q: 如何卸载？**  
  A: 运行安装目录中的 `uninstall.sh` 脚本，可完全卸载。

## 对比优势（与 OpenClaw）
| 特性         | MindX                                        | OpenClaw                          |
| ------------ | -------------------------------------------- | --------------------------------- |
| 架构设计     | 仿生大脑架构（潜意识+主意识）                | 控制平面架构                      |
| 模型支持     | 本地模型优先，支持云端 API                   | 主要依赖云端 API（Claude、GPT-4） |
| 数据隐私     | 完全本地运行，数据不上传云端                 | 部分功能依赖云端                  |
| 记忆系统     | 自动整理，越用越快                           | 基础存储，越用越慢                |
| 自助训练     | 支持训练专属模型，持续进化                   | 不支持                            |
| 部署方式     | 本地部署，无服务器依赖                       | 本地/云端部署                     |
| 资源消耗     | 轻量级，适合个人电脑                         | 资源消耗更高                      |
| 社交渠道支持 | 钉钉/微信/QQ/飞书/WhatsApp/Telegram 等全覆盖 | 仅支持 WhatsApp/Telegram 等部分   |

## 许可证
MindX 采用 MIT 许可证开源，核心技术 100% 自主可控，可自由使用、修改和分发。

## 免责声明
MindX 仅为个人辅助工具，请勿用于违法违规场景，使用过程中请遵守相关法律法规。